{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from six.moves import urllib\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "\n",
    "mnist_path = os.path.join(\".\", \"datasets\", \"mnist-original.mat\")\n",
    "\n",
    "if os.path.exists(mnist_path)==False:\n",
    "    # download dataset from github.\n",
    "    mnist_alternative_url = \"https://github.com/amplab/datascience-sp14/raw/master/lab7/mldata/mnist-original.mat\" \n",
    "    response = urllib.request.urlopen(mnist_alternative_url)\n",
    "    with open(mnist_path, \"wb\") as f:\n",
    "        content = response.read()\n",
    "        f.write(content)\n",
    "else:\n",
    "    mnist_raw = loadmat(mnist_path)\n",
    "    mnist = {\n",
    "        \"data\": mnist_raw[\"data\"].T,\n",
    "        \"target\": mnist_raw[\"label\"][0],\n",
    "        \"COL_NAMES\": [\"label\", \"data\"],\n",
    "        \"DESCR\": \"mldata.org dataset: mnist-original\",\n",
    "    }\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COL_NAMES': ['label', 'data'],\n",
       " 'DESCR': 'mldata.org dataset: mnist-original',\n",
       " 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'target': array([0., 0., 0., ..., 9., 9., 9.])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_digit = X[1]\n",
    "some_digit_image = some_digit.reshape(28,28)\n",
    "plt.imshow(some_digit_image,cmap= matplotlib.cm.binary, interpolation= \"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.将训练集与测试集分离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用此函数来生成 0 - 59999之间不重复的随机排列\n",
    "shuffle_index = np.random.permutation(60000) \n",
    "x_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.简化问题\n",
    "#### 2.1 训练一个二分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test ==5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "#随机梯度下降分类器并不是一个独立的算法，而是一系列利用随机梯度下降求解参数的算法的集合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train,y_train_5)\n",
    "# max_iter 被指定为算法训练epoch的次数\n",
    "# tol 被指定为算法停止的标准。在0.21版本中，默认为1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.20.0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__\n",
    "#看起来以上的随机梯度下降分类器模型所使用参数是训练epoch=5就停止"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.对性能的评估\n",
    "#### 3.1使用交叉验证测量准确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用第二章的知识对数据进行K折交叉检验\n",
    "#并且我们往往希望测试集当中的数据与训练集当中的数据有相同的分布\n",
    "#避免出现因为测试集中包含某一类样本过多使得精度度量失去意义 使用分层抽样解决此问题\n",
    "#此时分层抽样的依据往往是训练样本中的label分布\n",
    "#分层抽样在进行训练集与测试集分离以及进行交叉检验时都有涉及，需要注意\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88795\n"
     ]
    }
   ],
   "source": [
    "skfolds = StratifiedKFold(n_splits = 3, random_state=42)\n",
    "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
    "    #应产生总数为40000张的训练集和20000张的测试集\n",
    "    #训练集包含有36000张不是5的图片和4000张是5的图片\n",
    "    #测试集包含有18000张不是5的图片和2000张是5的图片\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = (y_train_5[train_index])\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = (y_train_5[test_index])\n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct / len(y_pred)) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
      "Train Index: [2 5] ,Test Index: [0 1 3 4]\n",
      "Train Index: [0 1 3 4] ,Test Index: [2 5]\n"
     ]
    }
   ],
   "source": [
    "# stratifiedKFold：保证训练集中每一类的比例是相同的（尽量）\n",
    "#n_splits代表产生k折 同样的，相当于产生k组数据    sss.split(X,y)中的\n",
    "#参数y则通过计算分布来使训练集与测试集中数据的类别分布一致\n",
    "#当总数为6的样本数被要求分为2折，其中分布为0.5,0.5时，由分布为先\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "X=np.array([[1,2],[3,4],[5,6],[7,8],[9,10],[11,12]])\n",
    "y=np.array([1,1,1,2,2,2])\n",
    "skf=StratifiedKFold(n_splits=2)\n",
    "print(skf)\n",
    "for train_index,test_index in skf.split(X,y):\n",
    "    print(\"Train Index:\",train_index,\",Test Index:\",test_index)\n",
    "    X_train,X_test=X[train_index],X[test_index]\n",
    "    y_train,y_test=y[train_index],y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit(n_splits=2, random_state=0, test_size=0.3,\n",
      "            train_size=None)\n",
      "Train Index: [2 5 1 3] ,Test Index: [0 4]\n",
      "Train Index: [0 4 3 1] ,Test Index: [2 5]\n"
     ]
    }
   ],
   "source": [
    "# StratifiedShuffleSplit 把数据集打乱顺序，然后划分测试集和训练集，\n",
    "# 训练集额和测试集的比例随机选定，训练集和测试集的比例的和可以小于1,\n",
    "#但是还要保证训练集中各类所占的比例是一样的\n",
    "#n_splits代表产生k折     test_size代表测试集所占比例  sss.split(X,y)中的\n",
    "#参数y则通过计算分布来使训练集与测试集中数据的类别分布一致\n",
    "    \n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "X=np.array([[1,2],[3,4],[5,6],[7,8],[9,10],[11,12]])\n",
    "y=np.array([1,1,1,2,2,2])\n",
    "sss=StratifiedShuffleSplit(n_splits=2,test_size=.3,random_state=0)\n",
    "#sss.get_n_splits(X,y)\n",
    "print(sss)\n",
    "for train_index,test_index in sss.split(X,y):\n",
    "    print(\"Train Index:\",train_index,\",Test Index:\",test_index)\n",
    "    X_train,X_test=X[train_index],X[test_index]\n",
    "    y_train,y_test=y[train_index],y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
