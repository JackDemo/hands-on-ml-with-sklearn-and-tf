{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = os.getcwd()\n",
    "CHAPTER_ID = \"tensorflow\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    \n",
    "def save_model(path_string):\n",
    "    return os.path.join(PROJECT_ROOT_DIR, path_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Administrator\\\\hands-on-ml-with-sklearn-and-tf'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Administrator\\\\hands-on-ml-with-sklearn-and-tf\\\\tmp/my_model.ckpt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(\"tmp/my_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3,name=\"x\")\n",
    "y = tf.Variable(4,name=\"y\")\n",
    "f = x*x*y + y+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "#way1\n",
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "#way2\n",
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "#way3\n",
    "init =  tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "#way4\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(6)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(7)\n",
    "x2.graph is graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.7465141e+01]\n",
      " [ 4.3573415e-01]\n",
      " [ 9.3382923e-03]\n",
      " [-1.0662201e-01]\n",
      " [ 6.4410698e-01]\n",
      " [-4.2513184e-06]\n",
      " [-3.7732250e-03]\n",
      " [-4.2664889e-01]\n",
      " [-4.4051403e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m,n = housing.data.shape\n",
    "\n",
    "housing_data_plus_bias = np.c_[np.ones((m,1)),housing.data]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias,dtype = tf.float32,name = \"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1),dtype=tf.float32,name=\"y\")\n",
    "\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)),XT),y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "print(theta_value)\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{\\theta}= \\left ( X^{T}\\cdot X \\right )^{-1}\\cdot X^{T}\\cdot y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing_data_plus_bias\n",
    "y = housing.target.reshape(-1,1)\n",
    "\n",
    "theta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.69419202e+01],\n",
       "       [ 4.36693293e-01],\n",
       "       [ 9.43577803e-03],\n",
       "       [-1.07322041e-01],\n",
       "       [ 6.45065694e-01],\n",
       "       [-3.97638942e-06],\n",
       "       [-3.78654265e-03],\n",
       "       [-4.21314378e-01],\n",
       "       [-4.34513755e-01]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = housing.data\n",
    "y = housing.target.reshape(-1,1)\n",
    "linear = LinearRegression()\n",
    "linear.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.69419202e+01],\n",
       "       [ 4.36693293e-01],\n",
       "       [ 9.43577803e-03],\n",
       "       [-1.07322041e-01],\n",
       "       [ 6.45065694e-01],\n",
       "       [-3.97638942e-06],\n",
       "       [-3.78654265e-03],\n",
       "       [-4.21314378e-01],\n",
       "       [-4.34513755e-01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.r_[linear.intercept_.reshape(-1,1),linear.coef_.reshape(-1,1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$MSE = \\frac{1}{m}\\sum_{i=1}^{m}(y_{i}-\\hat{y_{i}})^{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch =  0 MSE =  8.606744\n",
      "Epoch =  100 MSE =  6.8969636\n",
      "Epoch =  200 MSE =  6.0291204\n",
      "Epoch =  300 MSE =  5.5771976\n",
      "Epoch =  400 MSE =  5.3342395\n",
      "Epoch =  500 MSE =  5.1985183\n",
      "Epoch =  600 MSE =  5.1192565\n",
      "Epoch =  700 MSE =  5.0706162\n",
      "Epoch =  800 MSE =  5.0391335\n",
      "Epoch =  900 MSE =  5.017601\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import  StandardScaler\n",
    "\n",
    "learning_rate = 0.001\n",
    "n_epoch = 1000\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "m,n = housing.data.shape\n",
    "\n",
    "housing_data_plus_bias = np.c_[np.ones((m,1)),housing.data]\n",
    "#y = housing.target.reshape(-1,1)\n",
    "scale_housing_data_plus_bias = StandardScaler().fit_transform(housing_data_plus_bias)\n",
    "\n",
    "X = tf.constant(scale_housing_data_plus_bias,dtype=tf.float32,name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1),dtype=tf.float32,name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1,1),dtype=tf.float32)\n",
    "y_pred = tf.matmul(X,theta,name=\"prediction\")\n",
    "error = y_pred-y\n",
    "mse = tf.reduce_mean(tf.square(error),name=\"mse\")\n",
    "\n",
    "#使用TensorFlow自动梯度计算\n",
    "#gradients = 2/m * tf.matmul(tf.transpose(X),error)\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "training_op = tf.assign(theta,theta - learning_rate*gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epoch):\n",
    "        if epoch%100==0:\n",
    "            print(\"Epoch = \",epoch,\"MSE = \",mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.36589313],\n",
       "       [ 0.68926954],\n",
       "       [ 0.30235562],\n",
       "       [ 0.23903574],\n",
       "       [-0.18268274],\n",
       "       [ 0.10795614],\n",
       "       [ 0.04576566],\n",
       "       [ 0.02747855],\n",
       "       [ 0.10496338]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch =  0 MSE =  7.5898657\n",
      "Epoch =  100 MSE =  6.4475336\n",
      "Epoch =  200 MSE =  5.82356\n",
      "Epoch =  300 MSE =  5.465709\n",
      "Epoch =  400 MSE =  5.2503314\n",
      "Epoch =  500 MSE =  5.1148367\n",
      "Epoch =  600 MSE =  5.026291\n",
      "Epoch =  700 MSE =  4.966593\n",
      "Epoch =  800 MSE =  4.925329\n",
      "Epoch =  900 MSE =  4.896237\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.constant(scale_housing_data_plus_bias,dtype=tf.float32,name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1),dtype=tf.float32,name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1,1),dtype=tf.float32)\n",
    "y_pred = tf.matmul(X,theta,name=\"prediction\")\n",
    "error = y_pred-y\n",
    "mse = tf.reduce_mean(tf.square(error),name=\"mse\")\n",
    "\n",
    "#使用TensorFlow自动梯度计算\n",
    "#gradients = 2/m * tf.matmul(tf.transpose(X),error)\n",
    "#gradients = tf.gradients(mse, [theta])[0]\n",
    "#training_op = tf.assign(theta,theta - learning_rate*gradients)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse) \n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epoch):\n",
    "        if epoch%100==0:\n",
    "            print(\"Epoch = \",epoch,\"MSE = \",mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1,1),dtype=tf.float32)\n",
    "y_pred = tf.matmul(X,theta,name=\"prediction\")\n",
    "error = y_pred-y\n",
    "mse = tf.reduce_mean(tf.square(error),name=\"mse\")\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse) \n",
    "\n",
    "def fetch_batch(epoch,batch_index,batch_size):\n",
    "    np.random.seed(epoch*n_batches+batch_size)\n",
    "    indices = np.random.randint(m,size=batch_size)\n",
    "    X_batch = scale_housing_data_plus_bias[indices]\n",
    "    y_batch = housing.target.reshape(-1,1)[indices]\n",
    "    return X_batch,y_batch\n",
    "    \n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epoch):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch,y_batch = fetch_batch(epoch,batch_size,batch_size)\n",
    "            sess.run(training_op,feed_dict={X:X_batch,y:y_batch})\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epoch = 1000\n",
    "\n",
    "X = tf.constant(scale_housing_data_plus_bias,dtype=tf.float32,name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1),dtype=tf.float32,name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1,1),dtype=tf.float32)\n",
    "y_pred = tf.matmul(X,theta,name=\"prediction\")\n",
    "error = y_pred-y\n",
    "mse = tf.reduce_mean(tf.square(error),name=\"mse\")\n",
    "\n",
    "#使用TensorFlow自动梯度计算\n",
    "#gradients = 2/m * tf.matmul(tf.transpose(X),error)\n",
    "#gradients = tf.gradients(mse, [theta])[0]\n",
    "#training_op = tf.assign(theta,theta - learning_rate*gradients)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse) \n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tmp/my_model_final.ckpt\n",
      "Epoch =  0 MSE =  4.8064866\n",
      "Epoch =  100 MSE =  4.8063827\n",
      "Epoch =  200 MSE =  4.8062825\n",
      "Epoch =  300 MSE =  4.806185\n",
      "Epoch =  400 MSE =  4.806091\n",
      "Epoch =  500 MSE =  4.806\n",
      "Epoch =  600 MSE =  4.8059115\n",
      "Epoch =  700 MSE =  4.8058267\n",
      "Epoch =  800 MSE =  4.8057437\n",
      "Epoch =  900 MSE =  4.805664\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"tmp/my_model_final.ckpt\")#注意删除 sess.run(init)\n",
    "    for epoch in range(n_epoch):\n",
    "        if epoch % 100 == 0: # checkpoint every 100 epochs\n",
    "            save_path = saver.save(sess, save_model(\"tmp/my_model.ckpt\"))\n",
    "            print(\"Epoch = \",epoch,\"MSE = \",mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, save_model(\"tmp/my_model_final.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.94757867]\n",
      " [ 0.87069815]\n",
      " [ 0.23070854]\n",
      " [-0.07395332]\n",
      " [ 0.24779524]\n",
      " [ 0.18587995]\n",
      " [-1.1587862 ]\n",
      " [-0.88808215]\n",
      " [-0.84004384]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1,1),dtype=tf.float32)\n",
    "y_pred = tf.matmul(X,theta,name=\"prediction\")\n",
    "error = y_pred-y\n",
    "mse = tf.reduce_mean(tf.square(error),name=\"mse\")\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse) \n",
    "\n",
    "def fetch_batch(epoch,batch_index,batch_size):\n",
    "    np.random.seed(epoch*n_batches+batch_size)\n",
    "    indices = np.random.randint(m,size=batch_size)\n",
    "    X_batch = scale_housing_data_plus_bias[indices]\n",
    "    y_batch = housing.target.reshape(-1,1)[indices]\n",
    "    return X_batch,y_batch\n",
    "    \n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epoch):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch,y_batch = fetch_batch(epoch,batch_size,batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op,feed_dict={X:X_batch,y:y_batch})\n",
    "    best_theta = theta.eval()\n",
    "file_writer.close()\n",
    "print(best_theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.94757867]\n",
      " [ 0.87069815]\n",
      " [ 0.23070854]\n",
      " [-0.07395332]\n",
      " [ 0.24779524]\n",
      " [ 0.18587995]\n",
      " [-1.1587862 ]\n",
      " [-0.88808215]\n",
      " [-0.84004384]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1,1),dtype=tf.float32)\n",
    "y_pred = tf.matmul(X,theta,name=\"prediction\")\n",
    "with tf.name_scope(\"loss\") as scope:\n",
    "    error = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse) \n",
    "\n",
    "def fetch_batch(epoch,batch_index,batch_size):\n",
    "    np.random.seed(epoch*n_batches+batch_size)\n",
    "    indices = np.random.randint(m,size=batch_size)\n",
    "    X_batch = scale_housing_data_plus_bias[indices]\n",
    "    y_batch = housing.target.reshape(-1,1)[indices]\n",
    "    return X_batch,y_batch\n",
    "    \n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epoch):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch,y_batch = fetch_batch(epoch,batch_size,batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op,feed_dict={X:X_batch,y:y_batch})\n",
    "    best_theta = theta.eval()\n",
    "file_writer.close()\n",
    "print(best_theta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模块性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32,shape=(None,n_features),name=\"X\")\n",
    "w1 = tf.Variable(tf.random_normal((n_features,1)),name=\"w1\")\n",
    "w2 = tf.Variable(tf.random_normal((n_features,1)),name=\"w2\")\n",
    "b1 = tf.Variable(0.0,name=\"bias1\")\n",
    "b2 = tf.Variable(0.0,name=\"bias2\")\n",
    "z1 = tf.add(tf.matmul(X,w1),b1,name=\"z1\")\n",
    "z2 = tf.add(tf.matmul(X,w2),b2,name=\"z2\")\n",
    "relu1 = tf.maximum(z1,0,name=\"relu1\")\n",
    "relu2 = tf.maximum(z2,0,name=\"relu2\")\n",
    "output = tf.add(relu1,relu2,name=\"output\")\n",
    "\n",
    "\n",
    "file_writer = tf.summary.FileWriter(\"logs/relu1\", tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    w_shape = (int(X.get_shape()[1]),1)\n",
    "    w = tf.Variable(tf.random_normal(w_shape),name=\"weights\")\n",
    "    b = tf.Variable(0.0,name=\"bias\")\n",
    "    z = tf.add(tf.matmul(X,w),b,name=\"z\")\n",
    "    return tf.maximum(z,0.0,name=\"relu\")\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32,shape=(None,n_features),name=\"X\")\n",
    "relus = [relu(X) for i in range(5)] \n",
    "output = tf.add_n(relus,name=\"output\")\n",
    "\n",
    "file_writer = tf.summary.FileWriter(\"logs/relu2\", tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        w_shape = (int(X.get_shape()[1]),1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape),name=\"weights\")\n",
    "        b = tf.Variable(0.0,name=\"bias\")\n",
    "        z = tf.add(tf.matmul(X,w),b,name=\"z\")\n",
    "        return tf.maximum(z,0.0,name=\"relu\")\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32,shape=(None,n_features),name=\"X\")\n",
    "relus = [relu(X) for i in range(5)] \n",
    "output = tf.add_n(relus,name=\"output\")\n",
    "\n",
    "file_writer = tf.summary.FileWriter(\"logs/relu3\", tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    threshold = tf.get_variable(\"threshold\",shape=(),initializer=tf.constant_initializer(0.0))\n",
    "    w_shape = (int(X.get_shape()[1]),1)\n",
    "    w = tf.Variable(tf.random_normal(w_shape),name=\"weights\")\n",
    "    b = tf.Variable(0.0,name=\"bias\")\n",
    "    z = tf.add(tf.matmul(X,w),b,name=\"z\")\n",
    "    return tf.maximum(z,threshold,name=\"relu\")\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32,shape=(None,n_features),name=\"X\")\n",
    "relus = [] \n",
    "for relu_index in range(5):\n",
    "    with tf.variable_scope(\"relu\",reuse=(relu_index>=1)) as scope:\n",
    "        relus.append(relu(X))\n",
    "\n",
    "output = tf.add_n(relus,name=\"output\")\n",
    "\n",
    "file_writer = tf.summary.FileWriter(\"logs/relu4\", tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
